{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMrqgUxnECnuTVedaoaeJV2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 기초상식"],"metadata":{"id":"uBfmnLW3xbgy"}},{"cell_type":"markdown","source":["## 한국어에 잘 맞게 동작하는 사전 학습된 NLP 모델\n"],"metadata":{"id":"TQP1DbhPxgY5"}},{"cell_type":"markdown","source":["- SK 텔레콤에서 공개한 오픈소스\n","  - koBert, koGPT, koBart, ...\n","- 기타 다양한 모델이 존재 (전이학습)\n","  - Bert -> koBert -> xxBert -> ...\n","  - 모델 선택 + 전이학습 전략( 파인튜닝, 프럼프트 튜닝, 인컨텍스트 러닝(제로샷/원샷/ 퓨샷 러닝)\n","    - 09/08\n","      - 리뷰 긍부정 -> 이진분류 -> 파인튜닝\n","      - 챗봇 -> 코사인유사도계산 -> 제로샷 러닝\n","    - 추석이후\n","      - 다중분류\n","      - 요약\n","      - 토픽(키워드 추출,...)\n","      - 기계번역(?)\n","    - 자연어처리 용어 정리\n","      - 인베딩\n","      - 유사도\n","    - 자연어 관련 책 정리\n","      - "],"metadata":{"id":"rCKhlB0uxlXJ"}},{"cell_type":"markdown","source":["## 허깅페이스"],"metadata":{"id":"eBM9FnM7zvV6"}},{"cell_type":"markdown","source":["- 자연어 처리 스타트업이 개발한, 다양한 **트랜스포머** 모델(transformer.models)과 학습 스크립트(transformer.Trainer)를 제공하는 모듈\n","- **생태계**\n","- https://huggingface.co/\n","  - 유사한 생태계 : git\n","  - node : npm (npmjs.org)"],"metadata":{"id":"E8ZyS_qazylI"}},{"cell_type":"markdown","source":["## 트랜스포머"],"metadata":{"id":"fhONH3v80aFi"}},{"cell_type":"markdown","source":["- <a href=\"https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\">Attension is all you need 논문</a>\n","- 2017년 구글에서 발표\n","  - 여기서 등장한 모델이 트랜스포머\n","- 개념 정리후에 특징을 추가\n","- RNN의 한계를 극복하였다\n","  - 트렌스포머는 Bert, Bart, GPT등에 지대한 영향을 미쳤다"],"metadata":{"id":"j3GXqaNy0huy"}},{"cell_type":"markdown","source":["## 어텐션\n","\n","- 트랜스포머 체크할대 같이 점검"],"metadata":{"id":"PmvWFOEv0Wvz"}},{"cell_type":"markdown","source":["## koBert"],"metadata":{"id":"xa9q7vkLx12J"}},{"cell_type":"markdown","source":["- https://github.com/SKTBrain/KoBERT\n","- **한국어에 특화된 Bert**\n","  - Bert는 구글에서 개발\n","  - 다국어를 지원하는데, 한국어에 대한 비중이 낮아서, 한국어로 다운스트림 테스크(프로젝트)을 하는 경우 성능이 떨어진다\n","- 특징\n","  - 약 500만 개 문장,약 5,400만개 단어를 학습(토큰)\n","  - 실제 사내 챗봇, 법무 특허분야, 마케팅 분야등에 활용\n","  - 파이토치, 허깅페이스 트랜스포머, MXNet, ONNX등 공개지원하고 있다"],"metadata":{"id":"Uigxz54Hx3k4"}},{"cell_type":"markdown","source":["## MXNet"],"metadata":{"id":"s8J1w_o21x4b"}},{"cell_type":"markdown","source":["- apache 재단에서 AI 분야로 만든 플랫폼(**생태계**)"],"metadata":{"id":"KuERf9SK12-y"}},{"cell_type":"markdown","source":["## ONNX"],"metadata":{"id":"Kv_nDIW910T6"}},{"cell_type":"markdown","source":["- Open Neural Network Exchange는 AI 부문에서 혁신과 협업을 촉진하기 위해 기계 학습 알고리즘 및 소프트웨어 도구를 나타내는 개방형 표준을 설정하는 기술 회사 및 연구 기관의 오픈 소스 인공 지능 **생태계**입니다. ONNX는 GitHub에서 사용할 수 있습니다."],"metadata":{"id":"daNscoyv13xg"}},{"cell_type":"markdown","source":["# 기본 설치"],"metadata":{"id":"WAEoMPPJ2hF7"}},{"cell_type":"code","source":["# 트랜스포머 설치\n","# https://huggingface.co/docs/transformers/index\n","# 참고하는 소스의 버전에 따라 트랜스퍼머, 엔진(토치)등의 버전이 상이할수 있다(주의)\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SgT-MITL2j0x","executionInfo":{"status":"ok","timestamp":1662535788455,"user_tz":-540,"elapsed":15595,"user":{"displayName":"bs edu","userId":"16292712382043478147"}},"outputId":"662e507a-6cf2-40d3-f684-1c653eb4ad94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 4.8 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 24.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 40.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.3\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"aGj2JDoUzQEK"},"execution_count":null,"outputs":[]}]}